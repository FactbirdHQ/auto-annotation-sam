{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOG + SVM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "class HOGSVMBaseline:\n",
    "    \"\"\"\n",
    "    Traditional computer vision baseline using HOG features and SVM classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, hog_cell_size=(8, 8), hog_block_size=(2, 2), \n",
    "                 svm_kernel='rbf', svm_C=1.0):\n",
    "        # HOG parameters\n",
    "        self.hog_cell_size = hog_cell_size\n",
    "        self.hog_block_size = hog_block_size\n",
    "        \n",
    "        # SVM parameters\n",
    "        self.svm = SVC(kernel=svm_kernel, C=svm_C, probability=True)\n",
    "        \n",
    "        # For storing features and labels during training\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "    \n",
    "    def extract_features(self, image, mask):\n",
    "        \"\"\"Extract HOG features from the masked region\"\"\"\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "        \n",
    "        # Convert mask to numpy if it's not already\n",
    "        if not isinstance(mask, np.ndarray):\n",
    "            mask = np.array(mask)\n",
    "        \n",
    "        # Find bounding box of the mask\n",
    "        if mask.sum() > 0:\n",
    "            rows = np.any(mask, axis=1)\n",
    "            cols = np.any(mask, axis=0)\n",
    "            y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "            x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "            \n",
    "            # Add padding\n",
    "            padding = 10\n",
    "            y_min = max(0, y_min - padding)\n",
    "            y_max = min(mask.shape[0], y_max + padding)\n",
    "            x_min = max(0, x_min - padding)\n",
    "            x_max = min(mask.shape[1], x_max + padding)\n",
    "            \n",
    "            # Crop the image\n",
    "            if x_max > x_min and y_max > y_min:\n",
    "                image_array = np.array(image)\n",
    "                if len(image_array.shape) == 3:  # RGB\n",
    "                    cropped_image = image_array[y_min:y_max, x_min:x_max]\n",
    "                    cropped_mask = mask[y_min:y_max, x_min:x_max]\n",
    "                    mask_3d = np.expand_dims(cropped_mask, axis=2).repeat(3, axis=2)\n",
    "                    masked_image = cropped_image * mask_3d\n",
    "                else:  # Grayscale\n",
    "                    cropped_image = image_array[y_min:y_max, x_min:x_max]\n",
    "                    cropped_mask = mask[y_min:y_max, x_min:x_max]\n",
    "                    masked_image = cropped_image * cropped_mask\n",
    "            else:\n",
    "                masked_image = np.array(image)\n",
    "        else:\n",
    "            masked_image = np.array(image)\n",
    "        \n",
    "        # Convert to grayscale for HOG\n",
    "        if len(masked_image.shape) == 3:\n",
    "            gray_image = cv2.cvtColor(masked_image, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray_image = masked_image\n",
    "        \n",
    "        # Resize to a standard size\n",
    "        resized_image = cv2.resize(gray_image, (64, 64))\n",
    "        \n",
    "        # Extract HOG features\n",
    "        win_size = (64, 64)\n",
    "        block_size = (self.hog_block_size[0] * self.hog_cell_size[0],\n",
    "                      self.hog_block_size[1] * self.hog_cell_size[1])\n",
    "        block_stride = (self.hog_cell_size[0], self.hog_cell_size[1])\n",
    "        \n",
    "        hog = cv2.HOGDescriptor(win_size, block_size, block_stride, \n",
    "                               self.hog_cell_size, 9)\n",
    "        hog_features = hog.compute(resized_image)\n",
    "        \n",
    "        return hog_features.flatten()\n",
    "    \n",
    "    def fit(self, images, masks, labels=None):\n",
    "        \"\"\"Train the SVM classifier with HOG features\"\"\"\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Process inputs\n",
    "        if not isinstance(images, list):\n",
    "            images = [images]\n",
    "        \n",
    "        if not isinstance(masks, list):\n",
    "            masks = [masks]\n",
    "        \n",
    "        # Process each image and mask\n",
    "        for i in range(len(images)):\n",
    "            image = images[i]\n",
    "            \n",
    "            # Handle one image with multiple masks\n",
    "            if len(masks) > len(images) and i == 0:\n",
    "                image_masks = masks\n",
    "                \n",
    "                # Get corresponding labels\n",
    "                if labels is not None:\n",
    "                    if isinstance(labels, list) and len(labels) == len(masks):\n",
    "                        image_labels = labels\n",
    "                    else:\n",
    "                        image_labels = [1] * len(image_masks)\n",
    "                else:\n",
    "                    image_labels = [1] * len(image_masks)\n",
    "                \n",
    "                # Process each mask\n",
    "                for j, mask in enumerate(image_masks):\n",
    "                    try:\n",
    "                        feature = self.extract_features(image, mask)\n",
    "                        self.features.append(feature)\n",
    "                        self.labels.append(image_labels[j])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing mask {j}: {e}\")\n",
    "                        continue\n",
    "            # Handle mask lists\n",
    "            elif i < len(masks) and isinstance(masks[i], list):\n",
    "                image_masks = masks[i]\n",
    "                \n",
    "                # Get labels\n",
    "                if labels is not None:\n",
    "                    if isinstance(labels[i], list):\n",
    "                        image_labels = labels[i]\n",
    "                    else:\n",
    "                        image_labels = [labels[i]] * len(image_masks)\n",
    "                else:\n",
    "                    image_labels = [1] * len(image_masks)\n",
    "                \n",
    "                # Process each mask\n",
    "                for j, mask in enumerate(image_masks):\n",
    "                    try:\n",
    "                        feature = self.extract_features(image, mask)\n",
    "                        self.features.append(feature)\n",
    "                        self.labels.append(image_labels[j])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing mask {j}: {e}\")\n",
    "                        continue\n",
    "            elif i < len(masks):\n",
    "                # Single mask\n",
    "                mask = masks[i]\n",
    "                \n",
    "                # Get label\n",
    "                if labels is not None:\n",
    "                    label = labels[i]\n",
    "                else:\n",
    "                    label = 1\n",
    "                \n",
    "                try:\n",
    "                    feature = self.extract_features(image, mask)\n",
    "                    self.features.append(feature)\n",
    "                    self.labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing mask for image {i}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # Check if we have features\n",
    "        if len(self.features) > 0:\n",
    "            # Standardize features\n",
    "            scaler = StandardScaler()\n",
    "            scaled_features = scaler.fit_transform(self.features)\n",
    "            \n",
    "            # Train SVM\n",
    "            self.svm.fit(scaled_features, self.labels)\n",
    "            return True\n",
    "        else:\n",
    "            print(\"No features extracted. Cannot train SVM.\")\n",
    "            return False\n",
    "    \n",
    "    def predict(self, image, candidate_masks, return_probabilities=True):\n",
    "        \"\"\"Predict class of candidate masks\"\"\"\n",
    "        if not candidate_masks or len(candidate_masks) == 0:\n",
    "            if return_probabilities:\n",
    "                return [], []\n",
    "            else:\n",
    "                return []\n",
    "        \n",
    "        # Extract features\n",
    "        features = []\n",
    "        valid_masks = []\n",
    "        \n",
    "        for i, mask in enumerate(candidate_masks):\n",
    "            try:\n",
    "                feature = self.extract_features(image, mask)\n",
    "                features.append(feature)\n",
    "                valid_masks.append(mask)\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting features for mask {i}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not features:\n",
    "            if return_probabilities:\n",
    "                return [], []\n",
    "            else:\n",
    "                return []\n",
    "        \n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(features)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = self.svm.predict(scaled_features)\n",
    "        if return_probabilities:\n",
    "            probabilities = self.svm.predict_proba(scaled_features)\n",
    "            positive_probs = probabilities[:, 1] if probabilities.shape[1] > 1 else probabilities[:, 0]\n",
    "        \n",
    "        # Filter masks\n",
    "        filtered_indices = [i for i, pred in enumerate(predictions) if pred == 1]\n",
    "        filtered_masks = [valid_masks[i] for i in filtered_indices]\n",
    "        \n",
    "        if return_probabilities:\n",
    "            filtered_probs = [positive_probs[i] for i in filtered_indices]\n",
    "            return filtered_masks, filtered_probs\n",
    "        else:\n",
    "            return filtered_masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT + Bag-Of-Words Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIFTBagOfWordsBaseline:\n",
    "    \"\"\"\n",
    "    SIFT features with Bag of Visual Words and SVM classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters=100, svm_kernel='rbf', svm_C=1.0):\n",
    "        # SIFT detector\n",
    "        self.sift = cv2.SIFT_create()\n",
    "        \n",
    "        # K-means for visual vocabulary\n",
    "        self.kmeans = None\n",
    "        self.n_clusters = n_clusters\n",
    "        \n",
    "        # SVM classifier\n",
    "        self.svm = SVC(kernel=svm_kernel, C=svm_C, probability=True)\n",
    "        \n",
    "        # Feature scaling\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # For storing training data\n",
    "        self.bow_features = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Visual vocabulary (k-means clusters)\n",
    "        self.vocabulary = None\n",
    "    \n",
    "    def extract_local_features(self, image, mask):\n",
    "        \"\"\"Extract SIFT features from the masked region\"\"\"\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image_array = image\n",
    "        else:\n",
    "            image_array = np.array(image)\n",
    "        \n",
    "        if not isinstance(mask, np.ndarray):\n",
    "            mask = np.array(mask)\n",
    "        \n",
    "        # Find bounding box of the mask\n",
    "        if mask.sum() > 0:\n",
    "            rows = np.any(mask, axis=1)\n",
    "            cols = np.any(mask, axis=0)\n",
    "            y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "            x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "            \n",
    "            # Add padding\n",
    "            padding = 10\n",
    "            y_min = max(0, y_min - padding)\n",
    "            y_max = min(mask.shape[0], y_max + padding)\n",
    "            x_min = max(0, x_min - padding)\n",
    "            x_max = min(mask.shape[1], x_max + padding)\n",
    "            \n",
    "            # Check bounding box validity\n",
    "            if x_max <= x_min or y_max <= y_min:\n",
    "                cropped_region = image_array\n",
    "                mask_for_keypoints = np.ones(image_array.shape[:2], dtype=np.uint8)\n",
    "            else:\n",
    "                # Crop image and mask\n",
    "                cropped_region = image_array[y_min:y_max, x_min:x_max]\n",
    "                cropped_mask = mask[y_min:y_max, x_min:x_max]\n",
    "                \n",
    "                # Create mask for keypoint detection\n",
    "                if len(cropped_region.shape) == 3:\n",
    "                    mask_for_keypoints = cropped_mask.astype(np.uint8)\n",
    "                else:\n",
    "                    mask_for_keypoints = cropped_mask.astype(np.uint8)\n",
    "        else:\n",
    "            cropped_region = image_array\n",
    "            mask_for_keypoints = np.ones(image_array.shape[:2], dtype=np.uint8)\n",
    "        \n",
    "        # Convert to grayscale for SIFT\n",
    "        if len(cropped_region.shape) == 3:\n",
    "            gray_image = cv2.cvtColor(cropped_region, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray_image = cropped_region\n",
    "        \n",
    "        # Detect keypoints and descriptors\n",
    "        keypoints, descriptors = self.sift.detectAndCompute(gray_image, mask=mask_for_keypoints)\n",
    "        \n",
    "        # Return empty array if no keypoints found\n",
    "        if descriptors is None:\n",
    "            return np.array([])\n",
    "        \n",
    "        return descriptors\n",
    "    \n",
    "    def extract_bow_features(self, image, mask):\n",
    "        \"\"\"Extract Bag of Words features using visual vocabulary\"\"\"\n",
    "        if self.vocabulary is None:\n",
    "            raise ValueError(\"Visual vocabulary not created. Call fit() first.\")\n",
    "        \n",
    "        # Get local descriptors\n",
    "        descriptors = self.extract_local_features(image, mask)\n",
    "        \n",
    "        if descriptors.size == 0:\n",
    "            # No features found, return zeros\n",
    "            return np.zeros(self.n_clusters)\n",
    "        \n",
    "        # Assign each descriptor to a visual word\n",
    "        visual_words = self.kmeans.predict(descriptors)\n",
    "        \n",
    "        # Count occurrences of each visual word\n",
    "        bow_histogram = np.zeros(self.n_clusters)\n",
    "        for word in visual_words:\n",
    "            bow_histogram[word] += 1\n",
    "        \n",
    "        # Normalize the histogram\n",
    "        if bow_histogram.sum() > 0:\n",
    "            bow_histogram = bow_histogram / bow_histogram.sum()\n",
    "        \n",
    "        return bow_histogram\n",
    "    \n",
    "    def create_vocabulary(self, all_descriptors):\n",
    "        \"\"\"Create visual vocabulary by clustering descriptors\"\"\"\n",
    "        if all_descriptors.size == 0:\n",
    "            raise ValueError(\"No descriptors provided for vocabulary creation\")\n",
    "        \n",
    "        print(f\"Creating vocabulary with {self.n_clusters} visual words...\")\n",
    "        \n",
    "        # Limit the number of descriptors to avoid excessive memory usage\n",
    "        max_descriptors = 100000\n",
    "        if all_descriptors.shape[0] > max_descriptors:\n",
    "            indices = np.random.choice(all_descriptors.shape[0], max_descriptors, replace=False)\n",
    "            descriptors_sample = all_descriptors[indices]\n",
    "        else:\n",
    "            descriptors_sample = all_descriptors\n",
    "        \n",
    "        # Create vocabulary with k-means\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42, n_init=10)\n",
    "        self.kmeans.fit(descriptors_sample)\n",
    "        \n",
    "        self.vocabulary = self.kmeans.cluster_centers_\n",
    "    \n",
    "    def fit(self, images, masks, labels=None):\n",
    "        \"\"\"Train the SVM classifier with BoW features\"\"\"\n",
    "        # Process inputs\n",
    "        if not isinstance(images, list):\n",
    "            images = [images]\n",
    "        \n",
    "        if not isinstance(masks, list):\n",
    "            masks = [masks]\n",
    "        \n",
    "        # First pass: collect all descriptors for vocabulary creation\n",
    "        all_descriptors = []\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            image = images[i]\n",
    "            \n",
    "            # Handle one image with multiple masks\n",
    "            if len(masks) > len(images) and i == 0:\n",
    "                image_masks = masks\n",
    "                \n",
    "                for mask in image_masks:\n",
    "                    try:\n",
    "                        descriptors = self.extract_local_features(image, mask)\n",
    "                        if descriptors.size > 0:\n",
    "                            all_descriptors.append(descriptors)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error extracting descriptors: {e}\")\n",
    "            # Handle mask lists\n",
    "            elif i < len(masks) and isinstance(masks[i], list):\n",
    "                image_masks = masks[i]\n",
    "                \n",
    "                for mask in image_masks:\n",
    "                    try:\n",
    "                        descriptors = self.extract_local_features(image, mask)\n",
    "                        if descriptors.size > 0:\n",
    "                            all_descriptors.append(descriptors)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error extracting descriptors: {e}\")\n",
    "            elif i < len(masks):\n",
    "                # Single mask\n",
    "                mask = masks[i]\n",
    "                \n",
    "                try:\n",
    "                    descriptors = self.extract_local_features(image, mask)\n",
    "                    if descriptors.size > 0:\n",
    "                        all_descriptors.append(descriptors)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting descriptors: {e}\")\n",
    "        \n",
    "        # Check if we have descriptors\n",
    "        if not all_descriptors:\n",
    "            print(\"No descriptors extracted. Cannot create vocabulary.\")\n",
    "            return False\n",
    "        \n",
    "        # Concatenate all descriptors\n",
    "        all_descriptors = np.vstack(all_descriptors)\n",
    "        \n",
    "        # Create visual vocabulary\n",
    "        self.create_vocabulary(all_descriptors)\n",
    "        \n",
    "        # Second pass: extract BoW features for each mask\n",
    "        self.bow_features = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            image = images[i]\n",
    "            \n",
    "            # Handle one image with multiple masks\n",
    "            if len(masks) > len(images) and i == 0:\n",
    "                image_masks = masks\n",
    "                \n",
    "                # Get corresponding labels\n",
    "                if labels is not None:\n",
    "                    if isinstance(labels, list) and len(labels) == len(masks):\n",
    "                        image_labels = labels\n",
    "                    else:\n",
    "                        image_labels = [1] * len(image_masks)\n",
    "                else:\n",
    "                    image_labels = [1] * len(image_masks)\n",
    "                \n",
    "                # Process each mask\n",
    "                for j, mask in enumerate(image_masks):\n",
    "                    try:\n",
    "                        bow_feature = self.extract_bow_features(image, mask)\n",
    "                        self.bow_features.append(bow_feature)\n",
    "                        self.labels.append(image_labels[j])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing mask {j}: {e}\")\n",
    "                        continue\n",
    "            # Handle mask lists\n",
    "            elif i < len(masks) and isinstance(masks[i], list):\n",
    "                image_masks = masks[i]\n",
    "                \n",
    "                # Get labels\n",
    "                if labels is not None:\n",
    "                    if isinstance(labels[i], list):\n",
    "                        image_labels = labels[i]\n",
    "                    else:\n",
    "                        image_labels = [labels[i]] * len(image_masks)\n",
    "                else:\n",
    "                    image_labels = [1] * len(image_masks)\n",
    "                \n",
    "                # Process each mask\n",
    "                for j, mask in enumerate(image_masks):\n",
    "                    try:\n",
    "                        bow_feature = self.extract_bow_features(image, mask)\n",
    "                        self.bow_features.append(bow_feature)\n",
    "                        self.labels.append(image_labels[j])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing mask {j}: {e}\")\n",
    "                        continue\n",
    "            elif i < len(masks):\n",
    "                # Single mask\n",
    "                mask = masks[i]\n",
    "                \n",
    "                # Get label\n",
    "                if labels is not None:\n",
    "                    label = labels[i]\n",
    "                else:\n",
    "                    label = 1\n",
    "                \n",
    "                try:\n",
    "                    bow_feature = self.extract_bow_features(image, mask)\n",
    "                    self.bow_features.append(bow_feature)\n",
    "                    self.labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing mask for image {i}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # Check if we have features\n",
    "        if len(self.bow_features) > 0:\n",
    "            # Scale features\n",
    "            scaled_features = self.scaler.fit_transform(self.bow_features)\n",
    "            \n",
    "            # Train SVM\n",
    "            self.svm.fit(scaled_features, self.labels)\n",
    "            return True\n",
    "        else:\n",
    "            print(\"No BoW features extracted. Cannot train SVM.\")\n",
    "            return False\n",
    "    \n",
    "    def predict(self, image, candidate_masks, return_probabilities=True):\n",
    "        \"\"\"Predict class of candidate masks\"\"\"\n",
    "        if not candidate_masks or len(candidate_masks) == 0:\n",
    "            if return_probabilities:\n",
    "                return [], []\n",
    "            else:\n",
    "                return []\n",
    "            \n",
    "        if self.vocabulary is None:\n",
    "            print(\"Visual vocabulary not created. Call fit() first.\")\n",
    "            if return_probabilities:\n",
    "                return [], []\n",
    "            else:\n",
    "                return []\n",
    "        \n",
    "        # Extract BoW features\n",
    "        bow_features = []\n",
    "        valid_masks = []\n",
    "        \n",
    "        for i, mask in enumerate(candidate_masks):\n",
    "            try:\n",
    "                bow_feature = self.extract_bow_features(image, mask)\n",
    "                bow_features.append(bow_feature)\n",
    "                valid_masks.append(mask)\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting BoW features for mask {i}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not bow_features:\n",
    "            if return_probabilities:\n",
    "                return [], []\n",
    "            else:\n",
    "                return []\n",
    "        \n",
    "        # Scale features\n",
    "        scaled_features = self.scaler.transform(bow_features)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = self.svm.predict(scaled_features)\n",
    "        if return_probabilities:\n",
    "            probabilities = self.svm.predict_proba(scaled_features)\n",
    "            positive_probs = probabilities[:, 1] if probabilities.shape[1] > 1 else probabilities[:, 0]\n",
    "        \n",
    "        # Filter masks\n",
    "        filtered_indices = [i for i, pred in enumerate(predictions) if pred == 1]\n",
    "        filtered_masks = [valid_masks[i] for i in filtered_indices]\n",
    "        \n",
    "        if return_probabilities:\n",
    "            filtered_probs = [positive_probs[i] for i in filtered_indices]\n",
    "            return filtered_masks, filtered_probs\n",
    "        else:\n",
    "            return filtered_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
